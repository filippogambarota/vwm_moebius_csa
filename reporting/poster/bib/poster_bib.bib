@article{Wood2016,
abstract = {When we observe a facial expression of emotion, we often mimic it. This automatic mimicry reflects underlying sensorimotor simulation that supports accurate emotion recognition. Why this is so is becoming more obvious: emotions are patterns of expressive, behavioral, physiological, and subjective feeling responses. Activation of one component can therefore automatically activate other components. When people simulate a perceived facial expression, they partially activate the corresponding emotional state in themselves, which provides a basis for inferring the underlying emotion of the expresser. We integrate recent evidence in favor of a role for sensorimotor simulation in emotion recognition. We then connect this account to a domain-general understanding of how sensory information from multiple modalities is integrated to generate perceptual predictions in the brain. People's recognition and understanding of others' facial expressions is compromised by experimental (e.g., mechanical blocking) and clinical (e.g., facial paralysis and long-term pacifier use) disruptions to sensorimotor processing in the face.Emotion perception involves automatic activation of pre- and primary-motor and somatosensory cortices, and the inhibition of activity in sensorimotor networks reduces performance on subtle or challenging emotion recognition tasks.Sensorimotor simulation flexibly supports not only conceptual processing of facial expression but also, through cross-modal influences on visual processing, the building of a complete percept of the expression.While automatic and presumably nonconscious, sensorimotor simulation of facial expressions is modulated by the perceiver's social context and motivational state.},
author = {Wood, Adrienne and Rychlowska, Magdalena and Korb, Sebastian and Niedenthal, Paula},
doi = {10.1016/j.tics.2015.12.010},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Wood et al. - 2016 - Fashioning the Face Sensorimotor Simulation Contributes to Facial Expression Recognition.pdf:pdf},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {Cross-modal perceptual integration,Embodied simulation,Emotion perception,Facial expression of emotion,Facial mimicry},
number = {3},
pages = {227--240},
publisher = {Elsevier Ltd},
title = {{Fashioning the Face: Sensorimotor Simulation Contributes to Facial Expression Recognition}},
url = {http://dx.doi.org/10.1016/j.tics.2015.12.010},
volume = {20},
year = {2016}
}
@article{Zhang2008a,
abstract = {Limits on the storage capacity of working memory significantly affect cognitive abilities in a wide range of domains, but the nature of these capacity limits has been elusive. Some researchers have proposed that working memory stores a limited set of discrete, fixed-resolution representations, whereas others have proposed that working memory consists of a pool of resources that can be allocated flexibly to provide either a small number of high-resolution representations or a large number of low-resolution representations. Here we resolve this controversy by providing independent measures of capacity and resolution. We show that, when presented with more than a few simple objects, human observers store a high-resolution representation of a subset of the objects and retain no information about the others. Memory resolution varied over a narrow range that cannot be explained in terms of a general resource pool but can be well explained by a small set of discrete, fixed-resolution representations. {\textcopyright}2008 Nature Publishing Group.},
author = {Zhang, Weiwei and Luck, Steven J.},
doi = {10.1038/nature06860},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Zhang, Luck - 2008 - Discrete fixed-resolution representations in visual working memory.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7192},
pages = {233--235},
title = {{Discrete fixed-resolution representations in visual working memory}},
volume = {453},
year = {2008}
}
@article{Goldman2005,
abstract = {Recent studies of emotion mindreading reveal that for three emotions, fear, disgust, and anger, deficits in face-based recognition are paired with deficits in the production of the same emotion. What type of mindreading process would explain this pattern of paired deficits? The simulation approach and the theorizing approach are examined to determine their compatibility with the existing evidence. We conclude that the simulation approach offers the best explanation of the data. What computational steps might be used, however, in simulation-style emotion detection? Four alternative models are explored: a generate-and-test model, a reverse simulation model, a variant of the reverse simulation model that employs an "as if" loop, and an unmediated resonance model. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Goldman, Alvin I. and Sripada, Chandra Sekhar},
doi = {10.1016/j.cognition.2004.01.005},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Goldman, Sripada - 2005 - Simulationist models of face-based emotion recognition.pdf:pdf},
issn = {00100277},
journal = {Cognition},
keywords = {Anger,Disgust,Emotion,Facial feedback,Fear,Mirror neurons,Simulation theory,Theory of mind,Theory theory},
number = {3},
pages = {193--213},
title = {{Simulationist models of face-based emotion recognition}},
volume = {94},
year = {2005}
}
@article{Liesefeld2019,
abstract = {Visual working memory (VWM) is a core construct in the cognitive (neuro-)sciences, assumed to serve as a hub for information exchange and thus supporting a multitude of cognitive functions related to processing visual information. Here, we give an introduction into key terms and paradigms and an overview of ongoing debates in the field, to which the articles collected in this Special Issue on ‘Current Directions in Visual Working Memory Research' contribute. Our aim is to extract, from this overview, some ‘emerging' theoretical insights concerning questions such as the optimal way to examine VWM, which types of mental representations contribute to performance on VWM tasks, and how VWM keeps features from the same object together and apart from features of concurrently maintained objects (the binding problem).},
author = {Liesefeld, Heinrich Ren{\'{e}} and M{\"{u}}ller, Hermann J.},
doi = {10.1111/bjop.12377},
issn = {0007-1269},
journal = {British Journal of Psychology},
language = {en},
month = {may},
number = {2},
pages = {193--206},
shorttitle = {Current directions in visual working memory resear},
title = {{Current directions in visual working memory research: An introduction and emerging insights}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/bjop.12377},
volume = {110},
year = {2019}
}
@article{Gambarota2019,
abstract = {Visual working memory (VWM) is one of the most investigated cognitive systems functioning as a hub between low-and high-level processes. Remarkably, its role in human cognitive architecture makes it a stage of crucial importance for the study of socio-affective cognition, also in relation with psychopathology such as anxiety. Among socio-affective stimuli, faces occupy a place of first importance. How faces and facial expressions are encoded and maintained in VWM is the focus of this review. Within the main theoretical VWM models, we will review research comparing VWM representations of faces and of other classes of stimuli. We will further present previous work investigating if and how both static (i.e., ethnicity, trustworthiness and identity) and changeable (i.e., facial expressions) facial features are represented in VWM. Finally, we will examine research showing qualitative differences in VWM for face representations as a function of psychopathology and personality traits. The findings that we will review are not always coherent with each other, and for this reason we will highlight the main methodological differences as the main source of inconsistency. Finally, we will provide some suggestions for future research in this field in order to foster our understanding of representation of faces in VWM and its potential role in supporting socio-affective cognition.},
author = {Gambarota, Filippo and Sessa, Paola},
doi = {10.3389/fpsyg.2019.02392},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Gambarota, Sessa - 2019 - Visual Working Memory for Faces and Facial Expressions as a Useful “Tool” for Understanding Social and Affecti.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Affective cognition,Face,Facial expressions,Psychopathology,Social cognition,Visual working memory},
month = {oct},
number = {OCT},
pages = {1--7},
title = {{Visual Working Memory for Faces and Facial Expressions as a Useful “Tool” for Understanding Social and Affective Cognition}},
url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.02392/full},
volume = {10},
year = {2019}
}
@article{Wood2016a,
abstract = {Looking at another person's facial expression of emotion can trigger the same neural processes involved in producing the expression, and such responses play a functional role in emotion recognition. Disrupting individuals' facial action, for example, interferes with verbal emotion recognition tasks. We tested the hypothesis that facial responses also play a functional role in the perceptual processing of emotional expressions. We altered the facial action of participants with a gel facemask while they performed a task that involved distinguishing target expressions from highly similar distractors. Relative to control participants, participants in the facemask condition demonstrated inferior perceptual discrimination of facial expressions, but not of nonface stimuli. The findings suggest that somatosensory/motor processes involving the face contribute to the visual perceptual—and not just conceptual—processing of facial expressions. More broadly, our study contributes to growing evidence for the fundamentally interactive nature of the perceptual inputs from different sensory modalities.},
author = {Wood, Adrienne and Lupyan, Gary and Sherrin, Steven and Niedenthal, Paula},
doi = {10.3758/s13423-015-0974-5},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Cross-modal effects,Face perception,Facial expressions},
month = {aug},
number = {4},
pages = {1150--1156},
title = {{Altering sensorimotor feedback disrupts visual discrimination of facial expressions}},
url = {https://doi.org/10.3758/s13423-015-0974-5 http://link.springer.com/10.3758/s13423-015-0974-5},
volume = {23},
year = {2016}
}
@article{Sessa2018,
abstract = {Simulation models of facial expressions propose that sensorimotor regions may increase the clarity of facial expressions representations in extrastriate areas. We monitored the event-related potential marker of visual working memory (VWM) representations, namely the sustained posterior contralateral negativity (SPCN), also termed contralateral delay activity, while participants performed a change detection task including to-be-memorized faces with different intensities of anger. In one condition participants could freely use their facial mimicry during the encoding/VWM maintenance of the faces while in a different condition participants had their facial mimicry blocked by a gel. Notably, SPCN amplitude was reduced for faces in the blocked mimicry condition when compared to the free mimicry condition. This modulation interacted with the empathy levels of participants such that only participants with medium-high empathy scores showed such reduction of the SPCN amplitude when their mimicry was blocked. The SPCN amplitude was larger for full expressions when compared to neutral and subtle expressions, while subtle expressions elicited lower SPCN amplitudes than neutral faces. These findings provide evidence of a functional link between mimicry and VWM for faces and further shed light on how this memory system may receive feedbacks from sensorimotor regions during the processing of facial expressions.},
author = {Sessa, Paola and Lomoriello, Arianna Schiano and Luria, Roy},
doi = {10.1093/scan/nsy095},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Sessa, Lomoriello, Luria - 2018 - Neural measures of the causal role of observers' facial mimicry on visual working memory for facial ex.pdf:pdf},
issn = {17495024},
journal = {Social Cognitive and Affective Neuroscience},
keywords = {Empathy,Event-related potentials,Facial expressions,Facial mimicry,Visual working memory},
number = {12},
pages = {1281--1291},
title = {{Neural measures of the causal role of observers' facial mimicry on visual working memory for facial expressions}},
volume = {13},
year = {2018}
}
@article{Bogart2010,
abstract = {According to the reverse simulation model of embodied simulation theory, we recognize others' emotions by subtly mimicking their expressions, which allows us to feel the corresponding emotion through facial feedback. Previous studies examining whether facial mimicry is necessary for facial expression recognition were limited by potentially distracting manipulations intended to artificially restrict facial mimicry or very small samples of people with facial paralysis. We addressed these limitations by collecting the largest sample to date of people with Moebius syndrome, a condition characterized by congenital bilateral facial paralysis. In this Internet-based study, 37 adults with Moebius syndrome and 37 matched control participants completed a facial expression recognition task. People with Moebius syndrome did not differ from the control group or normative data in emotion recognition accuracy, and accuracy was not related to extent of ability to produce facial expressions. Our results do not support the hypothesis that reverse simulation with facial mimicry is necessary for facial expression recognition. {\textcopyright} 2009 Psychology Press.},
author = {Bogart, Kathleen Rives and Matsumoto, David},
doi = {10.1080/17470910903395692},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Bogart, Matsumoto - 2010 - Facial mimicry is not necessary to recognize emotion Facial expression recognition by people with Moebius syn.pdf:pdf},
issn = {17470919},
journal = {Social Neuroscience},
keywords = {Embodied simulation theory,Emotion recognition,Facial feedback,Mimicry,Moebius (Mobius) syndrome},
number = {2},
pages = {241--251},
title = {{Facial mimicry is not necessary to recognize emotion: Facial expression recognition by people with Moebius syndrome}},
volume = {5},
year = {2010}
}
@article{Calder2000,
abstract = {We present an investigation of facial expression recognition by three people (BC, LP, and NC) with Mobius syndrome, a congenital disorder producing facial paralysis. The participants were asked to identify the emotion displayed in 10 examples of facial expressions associated with each of 6 basic emotions from the Ekman and Friesen (1976) series. None of the three people with Mobius syndrome was significantly impaired on this task. On a second test of facial expression recognition using computer-morphed facial expressions, NC showed a statistically significant impairment, BC a borderline deficit, and LP was unimpaired. However, even when impairments were found, people with Mobius syndrome still recognised many of the facial expressions shown to them. The recognition of facial expressions by people who have never been able to produce such signals on their own faces demonstrates that the ability to produce facial expressions is not a necessary prerequisite of their recognition.},
author = {Calder, Andrew J. and Keane, Jill and Cole, Jonathan and Campbell, Ruth and Young, Andrew W.},
doi = {10.1080/026432900380490},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/Calder et al. - 2000 - Facial expression recognition by people with mobius syndrome.pdf:pdf},
issn = {02643294},
journal = {Cognitive Neuropsychology},
number = {1-3},
pages = {73--87},
title = {{Facial expression recognition by people with mobius syndrome}},
volume = {17},
year = {2000}
}
@article{DeStefani2019,
abstract = {According to the Darwinian perspective, facial expressions of emotions evolved to quickly communicate emotional states and would serve adaptive functions that promote social interactions. Embodied cognition theories suggest that we understand others' emotions by reproducing the perceived expression in our own facial musculature (facial mimicry) and the mere observation of a facial expression can evoke the corresponding emotion in the perceivers. Consequently, the inability to form facial expressions would affect the experience of emotional understanding. In this review, we aimed at providing account on the link between the lack of emotion production and the mechanisms of emotion processing. We address this issue by taking into account Moebius syndrome, a rare neurological disorder that primarily affects the muscles controlling facial expressions. Individuals with Moebius syndrome are born with facial paralysis and inability to form facial expressions. This makes them the ideal population to study whether facial mimicry is necessary for emotion understanding. Here, we discuss behavioral ambiguous/mixed results on emotion recognition deficits in Moebius syndrome suggesting the need to investigate further aspects of emotional processing such as the physiological responses associated with the emotional experience during developmental age.},
author = {{De Stefani}, Elisa and Nicolini, Ylenia and Belluardo, Mauro and Ferrari, Pier Francesco},
doi = {10.1111/gbb.12548},
file = {:C$\backslash$:/Users/Filippo/Google Drive/University/Mendeley/De Stefani et al. - 2019 - Congenital facial palsy and emotion processing The case of Moebius syndrome.pdf:pdf},
issn = {1601183X},
journal = {Genes, Brain and Behavior},
keywords = {Moebius syndrome,autonomic nervous system,congenital facial palsy,embodied simulation theories,emotion understanding,emotional processing,facial expressions,facial mimicry,mirror neuron system,recognition of emotions},
number = {1},
pages = {1--15},
title = {{Congenital facial palsy and emotion processing: The case of Moebius syndrome}},
volume = {18},
year = {2019}
}
