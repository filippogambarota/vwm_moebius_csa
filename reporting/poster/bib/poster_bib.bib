
@article{goldmanSimulationistModelsFacebased2005,
	title = {Simulationist models of face-based emotion recognition},
	volume = {94},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027704000538},
	doi = {10.1016/j.cognition.2004.01.005},
	abstract = {Recent studies of emotion mindreading reveal that for three emotions, fear, disgust, and anger, deficits in face-based recognition are paired with deficits in the production of the same emotion. What type of mindreading process would explain this pattern of paired deficits? The simulation approach and the theorizing approach are examined to determine their compatibility with the existing evidence. We conclude that the simulation approach offers the best explanation of the data. What computational steps might be used, however, in simulation-style emotion detection? Four alternative models are explored: a generate-and-test model, a reverse simulation model, a variant of the reverse simulation model that employs an “as if” loop, and an unmediated resonance model.},
	language = {en},
	number = {3},
	urldate = {2020-01-31},
	journal = {Cognition},
	author = {Goldman, Alvin I. and Sripada, Chandra Sekhar},
	month = jan,
	year = {2005},
	keywords = {Fear, Facial feedback, Emotion, Anger, Disgust, Mirror neurons, Simulation theory, Theory of mind, Theory theory},
	pages = {193--213},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\I9HRL7Y6\\Goldman and Sripada - 2005 - Simulationist models of face-based emotion recogni.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Filippo\\Zotero\\storage\\BR3SNGJU\\S0010027704000538.html:text/html}
}

@article{sessaNeuralMeasuresCausal2018,
	title = {Neural measures of the causal role of observers’ facial mimicry on visual working memory for facial expressions},
	volume = {13},
	issn = {1749-5016},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6277745/},
	doi = {10.1093/scan/nsy095},
	abstract = {Simulation models of facial expressions propose that sensorimotor regions may increase the clarity of facial expressions representations in extrastriate areas. We monitored the event-related potential marker of visual working memory (VWM) representations, namely the sustained posterior contralateral negativity (SPCN), also termed contralateral delay activity, while participants performed a change detection task including to-be-memorized faces with different intensities of anger. In one condition participants could freely use their facial mimicry during the encoding/VWM maintenance of the faces while in a different condition participants had their facial mimicry blocked by a gel. Notably, SPCN amplitude was reduced for faces in the blocked mimicry condition when compared to the free mimicry condition. This modulation interacted with the empathy levels of participants such that only participants with medium-high empathy scores showed such reduction of the SPCN amplitude when their mimicry was blocked. The SPCN amplitude was larger for full expressions when compared to neutral and subtle expressions, while subtle expressions elicited lower SPCN amplitudes than neutral faces. These findings provide evidence of a functional link between mimicry and VWM for faces and further shed light on how this memory system may receive feedbacks from sensorimotor regions during the processing of facial expressions.},
	number = {12},
	urldate = {2020-01-31},
	journal = {Social Cognitive and Affective Neuroscience},
	author = {Sessa, Paola and Schiano Lomoriello, Arianna and Luria, Roy},
	month = oct,
	year = {2018},
	pmid = {30365020},
	pmcid = {PMC6277745},
	pages = {1281--1291},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\TXG6NAC7\\Sessa et al. - 2018 - Neural measures of the causal role of observers’ f.pdf:application/pdf}
}

@article{bogartFacialMimicryNot2010,
	title = {Facial mimicry is not necessary to recognize emotion: {Facial} expression recognition by people with {Moebius} syndrome},
	volume = {5},
	issn = {1747-0927},
	shorttitle = {Facial mimicry is not necessary to recognize emotion},
	doi = {10.1080/17470910903395692},
	abstract = {According to the reverse simulation model of embodied simulation theory, we recognize others' emotions by subtly mimicking their expressions, which allows us to feel the corresponding emotion through facial feedback. Previous studies examining whether facial mimicry is necessary for facial expression recognition were limited by potentially distracting manipulations intended to artificially restrict facial mimicry or very small samples of people with facial paralysis. We addressed these limitations by collecting the largest sample to date of people with Moebius syndrome, a condition characterized by congenital bilateral facial paralysis. In this Internet-based study, 37 adults with Moebius syndrome and 37 matched control participants completed a facial expression recognition task. People with Moebius syndrome did not differ from the control group or normative data in emotion recognition accuracy, and accuracy was not related to extent of ability to produce facial expressions. Our results do not support the hypothesis that reverse simulation with facial mimicry is necessary for facial expression recognition.},
	language = {eng},
	number = {2},
	journal = {Social Neuroscience},
	author = {Bogart, Kathleen and Matsumoto, David},
	year = {2010},
	pmid = {19882440},
	keywords = {Case-Control Studies, Humans, Male, Middle Aged, Facial Expression, Emotions, Adult, Feedback, Psychological, Female, Mobius Syndrome, Neuropsychological Tests, Photic Stimulation, Recognition, Psychology, Surveys and Questionnaires, Young Adult},
	pages = {241--251}
}

@article{gambarotaVisualWorkingMemory2019,
	title = {Visual {Working} {Memory} for {Faces} and {Facial} {Expressions} as a {Useful} “{Tool}” for {Understanding} {Social} and {Affective} {Cognition}},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02392/full},
	doi = {10.3389/fpsyg.2019.02392},
	abstract = {Visual working memory (VWM) is one of the most investigated cognitive systems functioning as a hub between low- and high-level processes. Remarkably, its role in human cognitive architecture makes it a stage of crucial importance for the study of socio-affective cognition, also in relation with psychopathology such as anxiety. Among socio-affective stimuli, faces occupy a place of first importance. How faces and facial expressions are encoded and maintained in VWM is the focus of this review. Within the main theoretical VWM models, we will review research comparing VWM representations of faces and of other classes of stimuli. We will further present previous work investigating if and how both static (i.e. ethnicity, trustworthiness and identity) and dynamic (i.e. facial expressions) faces features are represented in VWM. Finally, we will examine research showing qualitative differences in VWM for face representations as a function of psychopathology and personality traits. The findings that we will review are not always coherent with each other, and for this reason we will highlight the main methodological differences as the main source of inconsistency. Finally, we will provide some suggestions for future research in this filed in order to foster our understanding of representation of faces in VWM and its potential role in supporting socio-affective cognition.},
	language = {English},
	urldate = {2020-01-31},
	journal = {Frontiers in Psychology},
	author = {Gambarota, Filippo and Sessa, Paola},
	year = {2019},
	keywords = {affective cognition, Face, Facial Expression, psychopatology, social cognition, visual working memory (VWM)},
	file = {Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\X39Z9Z3S\\Gambarota and Sessa - 2019 - Visual Working Memory for Faces and Facial Express.pdf:application/pdf}
}

@article{liesefeldCurrentDirectionsVisual2019,
	title = {Current directions in visual working memory research: {An} introduction and emerging insights},
	volume = {110},
	copyright = {© 2019 The British Psychological Society},
	issn = {2044-8295},
	shorttitle = {Current directions in visual working memory research},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/bjop.12377},
	doi = {10.1111/bjop.12377},
	abstract = {Visual working memory (VWM) is a core construct in the cognitive (neuro-)sciences, assumed to serve as a hub for information exchange and thus supporting a multitude of cognitive functions related to processing visual information. Here, we give an introduction into key terms and paradigms and an overview of ongoing debates in the field, to which the articles collected in this Special Issue on ‘Current Directions in Visual Working Memory Research’ contribute. Our aim is to extract, from this overview, some ‘emerging’ theoretical insights concerning questions such as the optimal way to examine VWM, which types of mental representations contribute to performance on VWM tasks, and how VWM keeps features from the same object together and apart from features of concurrently maintained objects (the binding problem).},
	language = {en},
	number = {2},
	urldate = {2020-01-31},
	journal = {British Journal of Psychology},
	author = {Liesefeld, Heinrich René and Müller, Hermann J.},
	year = {2019},
	pages = {193--206},
	file = {Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\XP7AJHGE\\Liesefeld and Müller - 2019 - Current directions in visual working memory resear.pdf:application/pdf;Snapshot:C\:\\Users\\Filippo\\Zotero\\storage\\4U579U6E\\bjop.html:text/html}
}

@article{zhangDiscreteFixedresolutionRepresentations2008,
	title = {Discrete fixed-resolution representations in visual working memory},
	volume = {453},
	copyright = {2008 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature06860},
	doi = {10.1038/nature06860},
	abstract = {Only a limited amount of information can be stored in short-term memory, but it is unclear whether we store high-quality representations of a small number of items or a larger number of items whose representation is of lower quality. Visual working memory is studied, particularly both the number of representations and the resolution of each representation, with the results favouring the idea that we store a smaller number of objects, with relatively discrete, fixed-resolution representations.},
	language = {en},
	number = {7192},
	urldate = {2020-01-31},
	journal = {Nature},
	author = {Zhang, Weiwei and Luck, Steven J.},
	month = may,
	year = {2008},
	pages = {233--235},
	file = {Snapshot:C\:\\Users\\Filippo\\Zotero\\storage\\2SZKCL4J\\nature06860.html:text/html;Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\GI4T2KYU\\Zhang and Luck - 2008 - Discrete fixed-resolution representations in visua.pdf:application/pdf}
}

@article{calderFacialExpressionRecognition2000,
	title = {Facial expression recognition by people with mobius syndrome},
	volume = {17},
	issn = {0264-3294},
	doi = {10.1080/026432900380490},
	abstract = {We present an investigation of facial expression recognition by three people (BC, LP, and NC) with Mobius syndrome, a congenital disorder producing facial paralysis. The participants were asked to identify the emotion displayed in 10 examples of facial expressions associated with each of 6 basic emotions from the Ekman and Friesen (1976) series. None of the three people with Mobius syndrome was significantly impaired on this task. On a second test of facial expression recognition using computer-morphed facial expressions, NC showed a statistically significant impairment, BC a borderline deficit, and LP was unimpaired. However, even when impairments were found, people with Mobius syndrome still recognised many of the facial expressions shown to them. The recognition of facial expressions by people who have never been able to produce such signals on their own faces demonstrates that the ability to produce facial expressions is not a necessary prerequisite of their recognition.},
	language = {eng},
	number = {1},
	journal = {Cognitive Neuropsychology},
	author = {Calder, A. J. and Keane, J. and Cole, J. and Campbell, R. and Young, A. W.},
	month = feb,
	year = {2000},
	pmid = {20945172},
	pages = {73--87}
}

@article{woodFashioningFaceSensorimotor2016,
	title = {Fashioning the {Face}: {Sensorimotor} {Simulation} {Contributes} to {Facial} {Expression} {Recognition}},
	volume = {20},
	issn = {1879-307X},
	shorttitle = {Fashioning the {Face}},
	doi = {10.1016/j.tics.2015.12.010},
	abstract = {When we observe a facial expression of emotion, we often mimic it. This automatic mimicry reflects underlying sensorimotor simulation that supports accurate emotion recognition. Why this is so is becoming more obvious: emotions are patterns of expressive, behavioral, physiological, and subjective feeling responses. Activation of one component can therefore automatically activate other components. When people simulate a perceived facial expression, they partially activate the corresponding emotional state in themselves, which provides a basis for inferring the underlying emotion of the expresser. We integrate recent evidence in favor of a role for sensorimotor simulation in emotion recognition. We then connect this account to a domain-general understanding of how sensory information from multiple modalities is integrated to generate perceptual predictions in the brain.},
	language = {eng},
	number = {3},
	journal = {Trends in Cognitive Sciences},
	author = {Wood, Adrienne and Rychlowska, Magdalena and Korb, Sebastian and Niedenthal, Paula},
	month = mar,
	year = {2016},
	pmid = {26876363},
	keywords = {Humans, cross-modal perceptual integration, embodied simulation, emotion perception, facial expression of emotion, facial mimicry, Face, Facial Expression, Emotions, Perception, Recognition, Psychology, Adaptation, Psychological, Culture, Physical Stimulation},
	pages = {227--240}
}

@article{woodAlteringSensorimotorFeedback2016,
	title = {Altering sensorimotor feedback disrupts visual discrimination of facial expressions},
	volume = {23},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-015-0974-5},
	doi = {10.3758/s13423-015-0974-5},
	abstract = {Looking at another person's facial expression of emotion can trigger the same neural processes involved in producing the expression, and such responses play a functional role in emotion recognition. Disrupting individuals' facial action, for example, interferes with verbal emotion recognition tasks. We tested the hypothesis that facial responses also play a functional role in the perceptual processing of emotional expressions. We altered the facial action of participants with a gel facemask while they performed a task that involved distinguishing target expressions from highly similar distractors. Relative to control participants, participants in the facemask condition demonstrated inferior perceptual discrimination of facial expressions, but not of nonface stimuli. The findings suggest that somatosensory/motor processes involving the face contribute to the visual perceptual—and not just conceptual—processing of facial expressions. More broadly, our study contributes to growing evidence for the fundamentally interactive nature of the perceptual inputs from different sensory modalities.},
	number = {4},
	journal = {Psychonomic Bulletin \& Review},
	author = {Wood, Adrienne and Lupyan, Gary and Sherrin, Steven and Niedenthal, Paula},
	month = aug,
	year = {2016},
	pages = {1150--1156}
}

@article{stefaniCongenitalFacialPalsy2019,
	title = {Congenital facial palsy and emotion processing: {The} case of {Moebius} syndrome},
	volume = {18},
	copyright = {© 2019 John Wiley \& Sons Ltd and International Behavioural and Neural Genetics Society},
	issn = {1601-183X},
	shorttitle = {Congenital facial palsy and emotion processing},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/gbb.12548},
	doi = {10.1111/gbb.12548},
	abstract = {According to the Darwinian perspective, facial expressions of emotions evolved to quickly communicate emotional states and would serve adaptive functions that promote social interactions. Embodied cognition theories suggest that we understand others' emotions by reproducing the perceived expression in our own facial musculature (facial mimicry) and the mere observation of a facial expression can evoke the corresponding emotion in the perceivers. Consequently, the inability to form facial expressions would affect the experience of emotional understanding. In this review, we aimed at providing account on the link between the lack of emotion production and the mechanisms of emotion processing. We address this issue by taking into account Moebius syndrome, a rare neurological disorder that primarily affects the muscles controlling facial expressions. Individuals with Moebius syndrome are born with facial paralysis and inability to form facial expressions. This makes them the ideal population to study whether facial mimicry is necessary for emotion understanding. Here, we discuss behavioral ambiguous/mixed results on emotion recognition deficits in Moebius syndrome suggesting the need to investigate further aspects of emotional processing such as the physiological responses associated with the emotional experience during developmental age.},
	language = {en},
	number = {1},
	urldate = {2020-02-01},
	journal = {Genes, Brain and Behavior},
	author = {Stefani, Elisa De and Nicolini, Ylenia and Belluardo, Mauro and Ferrari, Pier Francesco},
	year = {2019},
	keywords = {autonomic nervous system, congenital facial palsy, embodied simulation theories, emotion understanding, emotional processing, facial expressions, facial mimicry, mirror neuron system, Moebius syndrome, recognition of emotions},
	pages = {e12548},
	file = {Snapshot:C\:\\Users\\Filippo\\Zotero\\storage\\AF5TQMJ7\\gbb.html:text/html;Full Text PDF:C\:\\Users\\Filippo\\Zotero\\storage\\RTWVQVIF\\Stefani et al. - 2019 - Congenital facial palsy and emotion processing Th.pdf:application/pdf}
}